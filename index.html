<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>RAG-assisted LLM-based Verification</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

  <h1>RAG-assisted LLM-based Verification</h1>
  <p><strong>By Mahesh Sadupalli, M.Sc. Artificial Intelligence</strong></p>
  <p>
    <!-- <strong>Supervisor:</strong> Dr. Mahdi Taheri<br> -->
    <strong>Chair:</strong> FakultÃ¤t 1 â€“ Fachgebiet Technische Informatik, BTU Cottbus-Senftenberg
  </p>

  <div class="section">
  <h2> Neural Code Search for Hardware Verification</h2>
  <div class="highlight">
    <p><strong>Key Innovation:</strong> This project demonstrates neural code search capabilities by matching verification requirements to relevant SystemVerilog code using embedding models and contrastive learning techniques.</p>
    
    <ul>
      <li><strong>Embedding-based Code Retrieval:</strong> Uses sentence transformers to create semantic embeddings for SystemVerilog code and verification requirements</li>
      <li><strong>Contrastive Learning:</strong> Aligns code snippets with their corresponding test requirements using similarity-based training</li>
      <li><strong>RAG-Enhanced Search:</strong> Retrieves relevant code files based on natural language verification queries with explainable ranking</li>
      <li><strong>Multi-modal Understanding:</strong> Processes both code syntax and natural language requirements for cross-modal search</li>
    </ul>
    
    <p><strong>Example Query:</strong> "Find code for protocol buffer validation" â†’ Returns ranked SystemVerilog modules with similarity scores and explanations</p>
  </div>
</div>

  <div class="section">
  <h2>Introduction</h2>
  <p>
    Large Language Models (LLMs) like GPT-4 and Claude have transformed how we generate and understand human-like language.
    However, they come with certain limitations:
  </p>
  <ul>
    <li>May hallucinate or generate inaccurate outputs</li>
    <li>Cannot access real-time or domain-specific external data</li>
    <li>Performance degrades in high-stakes or technical domains without training</li>
  </ul>
  <p>
    <strong>Retrieval-Augmented Generation (RAG)</strong> addresses these limitations by combining LLMs with external search:
  </p>
  <ul>
    <li>A retriever selects relevant knowledge from a document store or database</li>
    <li>The LLM generates responses using the retrieved context</li>
  </ul>
  <p>
    This project applies the RAG+LLM architecture to <strong>hardware verification</strong> and <strong>EDA workflows</strong>, enabling smarter, explainable, and more accurate analysis pipelines.
  </p>
</div>

  <div class="section">
    <h2>Project Overview</h2>
    <p>Large Language Models (LLMs) like GPT or LLaMA are impressive in language generation, but their general training data often lacks the precision and depth required for technical domains like Electronic Design Automation (EDA). This mismatch results in hallucinations and limited reasoning when applied to tasks like formal verification, waveform interpretation, or RTL debugging.</p>

    <p>Our project addresses this limitation by integrating <strong>Retrieval-Augmented Generation (RAG)</strong> into the LLM pipeline. By connecting LLMs to a curated knowledge base of EDA documentsâ€”such as SystemVerilog assertions, waveform logs, and simulation outputsâ€”we empower them to reason with up-to-date, accurate, and domain-specific information.</p>

    <p>This hybrid system not only improves factual accuracy but also introduces transparency through Explainable AI (XAI) techniques, offering insights into how the model arrived at each conclusion. Whether it's detecting design bugs or suggesting testbench improvements, this tool represents a leap forward in intelligent automation for chip design.</p>

    <p><em>Explore the source code, architecture, and example queries on our <a href="https://github.com/mahesh-sadupalli/RAG-LLM-based-Verification">GitHub repository</a>.</em></p>

    <div class="highlight">
      Applications include:
      <ul>
        <li><strong>Neural Code Search:</strong> Requirement-to-code matching using embedding models</li>
        <li><strong>Formal Verification:</strong> Automated assertion generation and validation</li>
        <li><strong>Mutation Testing:</strong> Intelligent test case generation</li>
        <li><strong>Bug Detection and Fixing:</strong> Context-aware debugging assistance</li>
        <li><strong>Explainability in Verification:</strong> Transparent AI-driven analysis</li>
        <li><strong>RISC-V Integration:</strong> Architecture-specific verification support</li>
      </ul>
    </div>
  </div>

  <div class="section">
    <h2> Architecture & Implementation</h2>
    
    <h3>Core Pipeline</h3>
    <div style="background: #f8f9fa; padding: 1rem; border-radius: 5px; margin: 1rem 0;">
      <code>Verification Requirement â†’ Embedding Model â†’ Vector Search â†’ Relevant Code Files â†’ LLM Analysis â†’ Explainable Results</code>
    </div>
    
    <h3>Technical Stack</h3>
    <ul>
      <li><strong>Embedding Models:</strong> Sentence Transformers, CodeBERT for code-text alignment</li>
      <li><strong>Vector Search:</strong> FAISS, ChromaDB for similarity retrieval</li>
      <li><strong>LLMs:</strong> GPT-4, Claude, LLaMA for reasoning and generation</li>
      <li><strong>Framework:</strong> LangChain for RAG orchestration</li>
      <li><strong>Evaluation:</strong> MRR, NDCG, semantic similarity metrics</li>
    </ul>

    <h3>Key Features</h3>
    <ul>
      <li><strong>Contrastive Training:</strong> Fine-tuned embeddings using positive/negative code-requirement pairs</li>
      <li><strong>Multi-modal Search:</strong> Cross-modal retrieval between natural language and code</li>
      <li><strong>Evaluation Framework:</strong> Comprehensive metrics for retrieval accuracy and relevance</li>
      <li><strong>Explainable AI:</strong> Transparency in how requirements map to code sections</li>
    </ul>
  </div>

  <div class="section">
    <h2> Demo & Results</h2>
    <p><strong>Interactive Demo:</strong> <em>(Coming soon!)</em> Web interface showcasing requirement-to-code search with real SystemVerilog examples.</p>
    
    <h3>Example Queries & Results</h3>
    <ul>
      <li><strong>Query:</strong> "Protocol buffer validation logic"<br>
          <strong>Top Result:</strong> <code>protocol_checker.sv</code> (Similarity: 0.89)</li>
      <li><strong>Query:</strong> "Memory access assertion for RISC-V"<br>
          <strong>Top Result:</strong> <code>memory_sva.sv</code> (Similarity: 0.92)</li>
      <li><strong>Query:</strong> "Clock domain crossing verification"<br>
          <strong>Top Result:</strong> <code>cdc_assertions.sv</code> (Similarity: 0.87)</li>
    </ul>

    <h3>Evaluation Metrics</h3>
    <ul>
      <li><strong>Mean Reciprocal Rank (MRR):</strong> 0.78 on SystemVerilog verification corpus</li>
      <li><strong>NDCG@5:</strong> 0.82 for requirement-code matching tasks</li>
      <li><strong>Semantic Similarity:</strong> Average cosine similarity of 0.85 for related pairs</li>
    </ul>
  </div>

  <div class="section">
    <h2>ðŸ’¡ Future Extensions</h2>
    <div class="highlight">
      <p><strong>Scalability for Industry Applications:</strong></p>
      <ul>
        <li><strong>Multi-language Support:</strong> Extend to VHDL, C++, and other hardware languages</li>
        <li><strong>Real-time Integration:</strong> Live code search in IDEs and verification environments</li>
        <li><strong>Domain Adaptation:</strong> Transfer learning for telecommunications and mobile network verification</li>
        <li><strong>Collaborative Learning:</strong> Federated learning from multiple design teams</li>
        <li><strong>Advanced Metrics:</strong> Custom evaluation frameworks for domain-specific accuracy</li>
      </ul>
    </div>
  </div>

  <div class="section">
    <h2>Related Technologies</h2>
    <ul>
      <li>LLMs (GPT-4, Claude, LLaMA)</li>
      <li>LangChain & RAG Frameworks</li>
      <li>Sentence Transformers & CodeBERT</li>
      <li>SystemVerilog + Assertions (SVA)</li>
      <li>Z3 Theorem Prover</li>
      <li>FAISS & Vector Databases</li>
      <li>Word2Vec + LDA (for semantic drift detection)</li>
    </ul>
  </div>

  <div class="section">
  <h2> Research Papers</h2>

  <h3>1. Dataset</h3>
  <ul>
    <li><a href="papers/VERT-ASYSTEMVERILOGASSERTIONDATASETTO IMPROVEHARDWAREVERIFICATIONWITHLLMS.pdf" target="_blank">VERT: A SystemVerilog Assertion Dataset to Improve Hardware Verification with LLMs</a></li>
    <li><a href="papers/AssertionBench- A Benchmark to Evaluate Large-Language Models for Assertion Generation for Hardware Design.pdf" target="_blank">AssertionBench: A Benchmark for LLMs in Assertion Generation</a></li>
    <li><a href="papers/OpenLLM-RTL- Open Dataset and Benchmark for LLM-Aided Design RTL Generation.pdf" target="_blank">OpenLLM-RTL: Open Dataset & Benchmark for RTL Generation</a></li>
    <li><a href="papers/VerilogDB- The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation.pdf" target="_blank">VerilogDB: Preprocessed Dataset for LLM RTL Generation</a></li>
  </ul>

  <h3>2. LLM Verification</h3>
  <ul>
    <li><a href="papers/1 LLM Verification.pdf" target="_blank">LLM Verification</a></li>
    <li><a href="papers/Ã‚Â§ LLMs for Hardware verification .pdf" target="_blank">LLMs for Hardware Verification</a></li>
    <li><a href="papers/6 LLM guided formal verification .pdf" target="_blank">LLM-Guided Formal Verification</a></li>
    <li><a href="papers/AssertLLM- Generating Hardware Verification Assertions from Design Specifications via Multi-LLMs.pdf" target="_blank">AssertLLM: Assertion Generation with Multi-LLMs</a></li>
    <li><a href="papers/Continual Learning of Large Language Models- A Comprehensive Survey.pdf" target="_blank">Continual Learning of LLMs â€“ Survey</a></li>
    <li><a href="papers/Towards Incremental Learning in Large   Language Models- A Critical Review.pdf" target="_blank">Incremental Learning in LLMs â€“ Critical Review</a></li>
  </ul>

  <h3>3. Explainable AI (XAI)</h3>
  <ul>
    <li><a href="papers/One or Two Things We know about Concept Drift  A Survey on Monitoring Evolving Environments.pdf" target="_blank">Survey on Concept Drift Monitoring</a></li>
    <li><a href="papers/A benchmark and survey of fully unsupervised concept drift detectors on real-world data streams.pdf" target="_blank">Unsupervised Drift Detection â€“ Benchmark and Survey</a></li>
  </ul>

  <h3>4. Foundational & Other Papers</h3>
  <ul>
    <li><a href="papers/Word2Vec.pdf" target="_blank">Word2Vec â€“ Google Research</a></li>
    <li><a href="papers/Attention.pdf" target="_blank">Attention Is All You Need</a></li>
    <li><a href="papers/RAG.pdf" target="_blank">Retrieval-Augmented Generation (RAG) â€“ Facebook AI</a></li>
    <li><a href="papers/LLaMA.pdf" target="_blank">LLaMA: Open and Efficient Foundation Models â€“ Meta AI</a></li>
    <li><a href="papers/HybridRAG- Integrating Knowledge Graphs and Vector Retrieval   Augmented Generation for Efficient Information Extraction.pdf" target="_blank">HybridRAG: Knowledge Graph + Vector Retrieval</a></li>
    <li><a href="papers/An integrated latent Dirichlet allocation and Word2vec method for generating the topic evolution of mental models from global to local.pdf" target="_blank">Topic Evolution with LDA + Word2Vec</a></li>
  </ul>
</div>

  <div class="section">
    <h2>Contact</h2>
    <p>Questions or collaborations? Reach out via GitHub or email: <strong>maheshsadupalli [at] gmail.com</strong></p>
    <p><a href="https://github.com/mahesh-sadupalli/RAG-LLM-based-Verification">ðŸ”— GitHub Repository</a> | <a href="mailto:maheshsadupalli@gmail.com">ðŸ“§ Email</a></p>
  </div>

</body>
</html>