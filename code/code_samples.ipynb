{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural Code Search & Contrastive Learning Examples\n",
    "For Nokia AI FES Working Student Position\n",
    "\n",
    "This file demonstrates key technical implementations relevant to:\n",
    "- Neural code search using embedding models\n",
    "- Contrastive learning for code-requirement alignment  \n",
    "- RAG integration for context-aware responses\n",
    "- Evaluation metrics for retrieval systems\n",
    "\n",
    "Author: Mahesh Sadupalli\n",
    "Project: RAG-assisted LLM-based Verification\n",
    "\"\"\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Neural Code Search Implementation\n",
    "# =============================================================================\n",
    "\n",
    "class NeuralCodeSearch:\n",
    "    \"\"\"\n",
    "    Neural code search system using embedding models to match \n",
    "    requirements to relevant code files.\n",
    "    \n",
    "    Key Features:\n",
    "    - Semantic embedding of code and requirements\n",
    "    - Cosine similarity for ranking\n",
    "    - Configurable similarity thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.code_embeddings = None\n",
    "        self.code_files = []\n",
    "        self.similarity_threshold = 0.3\n",
    "    \n",
    "    def index_codebase(self, code_files: List[Dict]) -> None:\n",
    "        \"\"\"Create embeddings for entire codebase\"\"\"\n",
    "        self.code_files = code_files\n",
    "        code_texts = [self._extract_code_features(cf) for cf in code_files]\n",
    "        self.code_embeddings = self.model.encode(code_texts)\n",
    "        print(f\"Indexed {len(code_files)} code files\")\n",
    "    \n",
    "    def search(self, requirement: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Find most relevant code files for given requirement\"\"\"\n",
    "        if self.code_embeddings is None:\n",
    "            raise ValueError(\"Codebase not indexed. Call index_codebase() first.\")\n",
    "        \n",
    "        # Encode requirement\n",
    "        req_embedding = self.model.encode([requirement])\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = cosine_similarity(req_embedding, self.code_embeddings)[0]\n",
    "        \n",
    "        # Get top-k results above threshold\n",
    "        valid_indices = np.where(similarities >= self.similarity_threshold)[0]\n",
    "        top_indices = valid_indices[np.argsort(similarities[valid_indices])[::-1][:top_k]]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'file': self.code_files[idx]['name'],\n",
    "                'similarity': float(similarities[idx]),\n",
    "                'description': self.code_files[idx].get('description', ''),\n",
    "                'functions': self.code_files[idx].get('functions', [])\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_code_features(self, code_file: Dict) -> str:\n",
    "        \"\"\"Extract meaningful text features from code file for embedding\"\"\"\n",
    "        features = []\n",
    "        features.append(code_file.get('description', ''))\n",
    "        features.append(code_file.get('comments', ''))\n",
    "        features.append(' '.join(code_file.get('function_names', [])))\n",
    "        features.append(code_file.get('module_purpose', ''))\n",
    "        return ' '.join(filter(None, features))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Contrastive Learning for Code-Requirement Alignment\n",
    "# =============================================================================\n",
    "\n",
    "class ContrastiveCodeEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural encoder with contrastive learning for aligning code and requirements.\n",
    "    \n",
    "    Uses a projection head to map embeddings to a shared semantic space\n",
    "    where similar code-requirement pairs are close together.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_model_name: str, embedding_dim: int = 768, projection_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.base_model = SentenceTransformer(base_model_name)\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, texts: List[str]) -> torch.Tensor:\n",
    "        \"\"\"Encode texts through base model + projection head\"\"\"\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.base_model.encode(texts, convert_to_tensor=True)\n",
    "        \n",
    "        projected = self.projection(self.dropout(embeddings))\n",
    "        return F.normalize(projected, p=2, dim=1)\n",
    "\n",
    "\n",
    "def contrastive_loss(anchor: torch.Tensor, positive: torch.Tensor, \n",
    "                    negative: torch.Tensor, temperature: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Contrastive loss function for training code-requirement alignments.\n",
    "    \n",
    "    Args:\n",
    "        anchor: Requirement embeddings\n",
    "        positive: Matching code embeddings  \n",
    "        negative: Non-matching code embeddings\n",
    "        temperature: Scaling factor for similarity\n",
    "    \n",
    "    Returns:\n",
    "        Contrastive loss value\n",
    "    \"\"\"\n",
    "    # Compute similarities\n",
    "    pos_sim = torch.sum(anchor * positive, dim=1) / temperature\n",
    "    neg_sim = torch.sum(anchor * negative, dim=1) / temperature\n",
    "    \n",
    "    # InfoNCE-style contrastive loss\n",
    "    logits = torch.stack([pos_sim, neg_sim], dim=1)\n",
    "    labels = torch.zeros(anchor.size(0), dtype=torch.long, device=anchor.device)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_contrastive_model(model: ContrastiveCodeEncoder, \n",
    "                          train_data: List[Tuple], \n",
    "                          epochs: int = 10, \n",
    "                          learning_rate: float = 1e-4) -> None:\n",
    "    \"\"\"\n",
    "    Train contrastive model on requirement-code pairs.\n",
    "    \n",
    "    Args:\n",
    "        model: ContrastiveCodeEncoder to train\n",
    "        train_data: List of (requirement, positive_code, negative_code) tuples\n",
    "        epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (requirements, pos_codes, neg_codes) in enumerate(train_data):\n",
    "            \n",
    "            # Get embeddings\n",
    "            req_embeds = model(requirements)\n",
    "            pos_embeds = model(pos_codes)\n",
    "            neg_embeds = model(neg_codes)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = contrastive_loss(req_embeds, pos_embeds, neg_embeds)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_data)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Average Loss = {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. RAG Integration with Code Context\n",
    "# =============================================================================\n",
    "\n",
    "class CodeRAGSystem:\n",
    "    \"\"\"\n",
    "    Retrieval-Augmented Generation system that combines code search\n",
    "    with LLM generation for context-aware responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, code_search: NeuralCodeSearch, llm_client):\n",
    "        self.code_search = code_search\n",
    "        self.llm = llm_client\n",
    "        self.max_context_length = 2000  # Token limit for context\n",
    "        \n",
    "    def query_with_context(self, requirement: str, max_files: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        RAG pipeline: retrieve relevant code + generate LLM response.\n",
    "        \n",
    "        Args:\n",
    "            requirement: Natural language requirement/query\n",
    "            max_files: Maximum number of code files to include in context\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with response, retrieved files, and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: Retrieve relevant code files\n",
    "        relevant_code = self.code_search.search(requirement, top_k=max_files)\n",
    "        \n",
    "        if not relevant_code:\n",
    "            return {\n",
    "                'response': \"No relevant code found for this requirement.\",\n",
    "                'retrieved_files': [],\n",
    "                'similarity_scores': [],\n",
    "                'context_used': \"\"\n",
    "            }\n",
    "        \n",
    "        # Step 2: Build context from retrieved code\n",
    "        context = self._build_context(relevant_code, requirement)\n",
    "        \n",
    "        # Step 3: Generate LLM response with code context\n",
    "        prompt = self._create_prompt(requirement, context)\n",
    "        response = self._generate_response(prompt)\n",
    "        \n",
    "        return {\n",
    "            'response': response,\n",
    "            'retrieved_files': [r['file'] for r in relevant_code],\n",
    "            'similarity_scores': [r['similarity'] for r in relevant_code],\n",
    "            'context_used': context,\n",
    "            'prompt_length': len(prompt.split())\n",
    "        }\n",
    "    \n",
    "    def _build_context(self, relevant_code: List[Dict], requirement: str) -> str:\n",
    "        \"\"\"Build formatted context from retrieved code files\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        for i, result in enumerate(relevant_code, 1):\n",
    "            context_part = f\"\"\"\n",
    "            [{i}] File: {result['file']}\n",
    "            Similarity: {result['similarity']:.3f}\n",
    "            Description: {result['description']}\n",
    "            Key Functions: {', '.join(result.get('functions', []))}\n",
    "            \"\"\"\n",
    "            context_parts.append(context_part.strip())\n",
    "        \n",
    "        return '\\n\\n'.join(context_parts)\n",
    "    \n",
    "    def _create_prompt(self, requirement: str, context: str) -> str:\n",
    "        \"\"\"Create structured prompt for LLM\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are a hardware verification expert. Based on the following relevant code files, \n",
    "        provide guidance for this verification requirement.\n",
    "\n",
    "        REQUIREMENT: {requirement}\n",
    "\n",
    "        RELEVANT CODE FILES:\n",
    "        {context}\n",
    "\n",
    "        Please provide:\n",
    "        1. Specific implementation guidance\n",
    "        2. Potential issues to consider  \n",
    "        3. Best practices for this use case\n",
    "        4. References to the most relevant files above\n",
    "\n",
    "        Response:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate response using LLM (placeholder for actual LLM call)\"\"\"\n",
    "        # In real implementation, this would call OpenAI, Claude, etc.\n",
    "        # For demo purposes, return a structured placeholder\n",
    "        return \"\"\"Based on the retrieved code files, I recommend:\n",
    "\n",
    "        1. Implementation: Start with the highest similarity file as a template\n",
    "        2. Testing: Ensure coverage of edge cases mentioned in the code comments  \n",
    "        3. Integration: Check compatibility with existing verification framework\n",
    "        4. Validation: Use assertion patterns from similar modules\n",
    "\n",
    "        The retrieved files provide excellent starting points for your implementation.\"\"\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Evaluation Metrics for Code Search Systems\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_mrr(ranked_results: List[List[bool]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank for search results.\n",
    "    \n",
    "    Args:\n",
    "        ranked_results: List of lists, where each inner list contains boolean\n",
    "                       values indicating if the result at that rank is relevant\n",
    "    \n",
    "    Returns:\n",
    "        Mean Reciprocal Rank score\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    for results in ranked_results:\n",
    "        reciprocal_rank = 0\n",
    "        for rank, is_relevant in enumerate(results, 1):\n",
    "            if is_relevant:\n",
    "                reciprocal_rank = 1.0 / rank\n",
    "                break\n",
    "        reciprocal_ranks.append(reciprocal_rank)\n",
    "    \n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "\n",
    "def calculate_ndcg_at_k(ranked_results: List[List[float]], k: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Normalized Discounted Cumulative Gain at K.\n",
    "    \n",
    "    Args:\n",
    "        ranked_results: List of lists containing relevance scores\n",
    "        k: Cutoff rank for evaluation\n",
    "        \n",
    "    Returns:\n",
    "        NDCG@K score\n",
    "    \"\"\"\n",
    "    def dcg_at_k(relevance_scores: List[float], k: int) -> float:\n",
    "        \"\"\"Calculate DCG at K\"\"\"\n",
    "        dcg = 0\n",
    "        for i, score in enumerate(relevance_scores[:k]):\n",
    "            dcg += score / np.log2(i + 2)  # +2 because log2(1) = 0\n",
    "        return dcg\n",
    "    \n",
    "    ndcg_scores = []\n",
    "    for results in ranked_results:\n",
    "        # Actual DCG\n",
    "        actual_dcg = dcg_at_k(results, k)\n",
    "        \n",
    "        # Ideal DCG (sorted in descending order)\n",
    "        ideal_dcg = dcg_at_k(sorted(results, reverse=True), k)\n",
    "        \n",
    "        # NDCG\n",
    "        ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Example Usage & Demo\n",
    "# =============================================================================\n",
    "\n",
    "def demo_neural_code_search():\n",
    "    \"\"\"Demonstration of neural code search system\"\"\"\n",
    "    \n",
    "    # Sample SystemVerilog code database\n",
    "    sample_codebase = [\n",
    "        {\n",
    "            'name': 'protocol_checker.sv',\n",
    "            'description': 'Protocol buffer validation and checking logic',\n",
    "            'comments': 'Validates incoming protocol buffers against specification',\n",
    "            'function_names': ['validate_protocol', 'check_buffer_integrity', 'parse_header'],\n",
    "            'module_purpose': 'Protocol validation and verification'\n",
    "        },\n",
    "        {\n",
    "            'name': 'memory_sva.sv', \n",
    "            'description': 'Memory access assertions for RISC-V processor',\n",
    "            'comments': 'SystemVerilog assertions for memory subsystem verification',\n",
    "            'function_names': ['check_memory_access', 'assert_address_valid', 'verify_data_integrity'],\n",
    "            'module_purpose': 'Memory verification and assertion checking'\n",
    "        },\n",
    "        {\n",
    "            'name': 'cdc_assertions.sv',\n",
    "            'description': 'Clock domain crossing verification assertions',\n",
    "            'comments': 'Verifies safe clock domain crossing implementations',\n",
    "            'function_names': ['check_cdc_safety', 'verify_synchronizer', 'assert_metastability'],\n",
    "            'module_purpose': 'Clock domain crossing safety verification'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Initialize search system\n",
    "    search_system = NeuralCodeSearch()\n",
    "    search_system.index_codebase(sample_codebase)\n",
    "    \n",
    "    # Example queries\n",
    "    test_queries = [\n",
    "        \"Protocol buffer validation logic\",\n",
    "        \"Memory access assertion for RISC-V\", \n",
    "        \"Clock domain crossing verification\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=== Neural Code Search Demo ===\\n\")\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"Query: '{query}'\")\n",
    "        results = search_system.search(query, top_k=3)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"  {i}. {result['file']} (similarity: {result['similarity']:.3f})\")\n",
    "            print(f\"     {result['description']}\")\n",
    "        print()\n",
    "    \n",
    "    return search_system\n",
    "\n",
    "\n",
    "def demo_evaluation_metrics():\n",
    "    \"\"\"Demonstration of evaluation metrics for code search\"\"\"\n",
    "    \n",
    "    # Sample evaluation data\n",
    "    # Each list represents ranked results for a query (True = relevant, False = not relevant)\n",
    "    sample_ranked_results = [\n",
    "        [True, False, True, False, False],   # Query 1: relevant items at rank 1 and 3\n",
    "        [False, True, False, True, False],   # Query 2: relevant items at rank 2 and 4  \n",
    "        [True, True, False, False, False]    # Query 3: relevant items at rank 1 and 2\n",
    "    ]\n",
    "    \n",
    "    # Sample relevance scores (0-1 scale)\n",
    "    sample_relevance_scores = [\n",
    "        [0.9, 0.1, 0.8, 0.2, 0.0],\n",
    "        [0.0, 0.85, 0.1, 0.75, 0.0],\n",
    "        [0.95, 0.9, 0.1, 0.0, 0.0]\n",
    "    ]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mrr_score = calculate_mrr(sample_ranked_results)\n",
    "    ndcg_score = calculate_ndcg_at_k(sample_relevance_scores, k=5)\n",
    "    \n",
    "    print(\"=== Evaluation Metrics Demo ===\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {mrr_score:.3f}\")\n",
    "    print(f\"NDCG@5: {ndcg_score:.3f}\")\n",
    "    \n",
    "    return mrr_score, ndcg_score\n",
    "\n",
    "\n",
    "def demo_rag_system():\n",
    "    \"\"\"Demonstration of RAG integration with code search\"\"\"\n",
    "    \n",
    "    # Initialize components\n",
    "    search_system = demo_neural_code_search()\n",
    "    \n",
    "    # Mock LLM client (in real implementation, this would be OpenAI, Claude, etc.)\n",
    "    class MockLLMClient:\n",
    "        def generate(self, prompt, max_tokens=500):\n",
    "            return \"Generated response based on retrieved code context...\"\n",
    "    \n",
    "    llm_client = MockLLMClient()\n",
    "    rag_system = CodeRAGSystem(search_system, llm_client)\n",
    "    \n",
    "    # Example RAG query\n",
    "    query = \"I need to implement protocol buffer validation for a new communication module\"\n",
    "    \n",
    "    print(\"=== RAG System Demo ===\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    result = rag_system.query_with_context(query, max_files=2)\n",
    "    \n",
    "    print(\"Retrieved Files:\")\n",
    "    for file, score in zip(result['retrieved_files'], result['similarity_scores']):\n",
    "        print(f\"  - {file} (similarity: {score:.3f})\")\n",
    "    \n",
    "    print(f\"\\nGenerated Response:\\n{result['response']}\")\n",
    "    print(f\"\\nContext Length: {len(result['context_used'].split())} words\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main demonstration showcasing all key components:\n",
    "    1. Neural code search with embedding models\n",
    "    2. Evaluation metrics (MRR, NDCG)  \n",
    "    3. RAG integration for context-aware responses\n",
    "    \n",
    "    This demonstrates the core technologies needed for Nokia's\n",
    "    AI FES position: neural code search, contrastive learning concepts,\n",
    "    and RAG implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Neural Code Search & RAG Demonstration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Run demonstrations\n",
    "    demo_neural_code_search()\n",
    "    demo_evaluation_metrics() \n",
    "    demo_rag_system()\n",
    "    \n",
    "    print(\"\\n Demo completed successfully!\")\n",
    "    print(\"\\nKey Technologies Demonstrated:\")\n",
    "    print(\"- Neural code search using embedding models\")\n",
    "    print(\"- Contrastive learning for code-requirement alignment\")\n",
    "    print(\"- RAG integration with LLM generation\")\n",
    "    print(\"- Evaluation metrics (MRR, NDCG)\")\n",
    "    print(\"- End-to-end AI lifecycle implementation\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Configuration and Requirements\n",
    "# =============================================================================\n",
    "\n",
    "# Required packages for this implementation:\n",
    "\"\"\"\n",
    "sentence-transformers>=2.2.0\n",
    "torch>=1.12.0\n",
    "scikit-learn>=1.1.0\n",
    "numpy>=1.21.0\n",
    "\"\"\"\n",
    "\n",
    "# Example requirements.txt content:\n",
    "REQUIREMENTS = \"\"\"\n",
    "sentence-transformers==2.2.2\n",
    "torch==1.13.1\n",
    "scikit-learn==1.2.1\n",
    "numpy==1.24.0\n",
    "faiss-cpu==1.7.3\n",
    "langchain==0.1.0\n",
    "openai==1.0.0\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
